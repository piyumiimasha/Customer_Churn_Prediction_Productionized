# Spark-Based Customer Churn Prediction Pipeline

This document describes the distributed processing capabilities of the Customer Churn Prediction pipeline using Apache Spark and PySpark MLlib.

## üöÄ Overview

The pipeline has been enhanced with PySpark DataFrames and MLlib APIs to support distributed processing and scalability. This allows the system to handle large datasets efficiently across multiple cores or cluster nodes.

## üìÅ Spark Components

### Core Files

- **`src/spark_session.py`** - Centralized SparkSession management with optimized configurations
- **`src/spark_data_pipeline.py`** - Complete data preprocessing pipeline using Spark DataFrames
- **`src/spark_model_trainer.py`** - Distributed model training using Spark MLlib
- **`pipelines/unified_spark_pipeline.py`** - End-to-end pipeline orchestrating data processing and model training

### Configuration

- **`config.yml`** - Contains Spark configuration settings for both local and cluster deployments
- **`utils/config.py`** - Enhanced with `get_spark_config()` function

## üîß Architecture

### 1. Spark Session Management
```python
from spark_session import create_spark_session, configure_spark_for_ml

# Create optimized SparkSession
spark = create_spark_session(
    app_name="ChurnPredictionPipeline",
    master="local[*]",  # Use all available cores
    config_options={
        "spark.sql.adaptive.enabled": "true",
        "spark.sql.execution.arrow.pyspark.enabled": "true",
        # ... more optimizations
    }
)
```

### 2. Distributed Data Processing

#### Features:
- **Adaptive Query Execution (AQE)** for automatic query optimization
- **Arrow optimization** for better pandas/Spark interoperability
- **Automatic data type inference** and schema validation
- **Distributed missing value handling** using Spark ML Imputer
- **Scalable outlier detection** using IQR method
- **Feature engineering** with Spark SQL functions

#### Pipeline Stages:
1. **Data Loading** - Supports CSV, Excel, Parquet formats
2. **Data Quality Analysis** - Missing values, duplicates, statistics
3. **Missing Value Imputation** - Mean for numerical, mode for categorical
4. **Outlier Detection** - IQR-based detection with configurable thresholds
5. **Feature Engineering** - Derived features, binning, aggregations
6. **Feature Preprocessing** - StringIndexer, OneHotEncoder, StandardScaler
7. **Data Splitting** - Stratified train/test split with caching

### 3. Distributed Model Training

#### Supported Algorithms:
- **Gradient Boosted Trees (GBT)** - Primary model with hyperparameter tuning
- **Random Forest** - Ensemble method with feature importance
- **Logistic Regression** - Linear baseline with regularization
- **Decision Tree** - Interpretable single tree model

#### ML Pipeline Features:
- **Automated hyperparameter tuning** using CrossValidator or TrainValidationSplit
- **Parallel model training** across multiple algorithms
- **Comprehensive evaluation** with multiple metrics (ROC-AUC, Accuracy, F1, etc.)
- **Feature importance extraction** for model interpretability
- **Model comparison** and automatic best model selection

### 4. Performance Optimizations

#### Data Processing:
- **Parquet format** for efficient storage and faster I/O
- **DataFrame caching** for iterative operations
- **Partition optimization** based on data size
- **Predicate pushdown** for filtered operations

#### ML Training:
- **Parallel cross-validation** with configurable fold count
- **Distributed hyperparameter search** across parameter grids
- **Memory-efficient model storage** using Spark ML Pipeline format
- **Automatic cleanup** of cached data and temporary files

## üöÄ Usage

### 1. Local Development
```bash
# Run complete Spark pipeline
python pipelines/unified_spark_pipeline.py

# Run individual components
python src/spark_data_pipeline.py
python src/spark_model_trainer.py
```

### 2. Configuration
Update `config.yml` for your environment:
```yaml
spark:
  app_name: "ChurnPredictionPipeline"
  master: "local[*]"  # Local mode
  # OR for cluster:
  # master: "spark://master-node:7077"
  
  config_options:
    "spark.executor.memory": "4g"
    "spark.executor.cores": "2"
    "spark.sql.shuffle.partitions": "200"
```

### 3. Cluster Deployment
For production cluster deployment:
```python
# Update spark configuration for cluster
spark_config = {
    "master": "spark://your-cluster-master:7077",
    "spark.executor.memory": "8g",
    "spark.executor.cores": "4", 
    "spark.num.executors": "10",
    "spark.driver.memory": "4g"
}

pipeline = UnifiedSparkPipeline()
pipeline.run_complete_pipeline(
    data_path="hdfs://path/to/large/dataset.parquet",
    output_dir="hdfs://path/to/output"
)
```

## üìä Performance Benefits

### Scalability
- **Horizontal scaling** - Add more nodes to handle larger datasets
- **Vertical scaling** - Utilize all CPU cores and memory efficiently
- **Automatic partitioning** - Data automatically distributed across cluster

### Speed Improvements
- **Lazy evaluation** - Operations optimized before execution
- **In-memory caching** - Frequent datasets kept in memory
- **Columnar storage** - Parquet format for faster analytical queries
- **Vectorized operations** - Arrow-based processing for numerical computations

### Resource Management
- **Dynamic resource allocation** - Automatically adjust executors based on workload
- **Memory management** - Efficient memory usage with configurable fractions
- **Fault tolerance** - Automatic recovery from node failures

## üîç Monitoring and Debugging

### Spark UI
Access the Spark UI at `http://localhost:4040` during execution to monitor:
- Job progress and stages
- Task execution details
- Memory usage and GC metrics
- SQL query plans and optimizations

### Logging
Comprehensive logging at multiple levels:
```python
# Enable different log levels
spark.sparkContext.setLogLevel("INFO")  # INFO, WARN, ERROR, DEBUG
```

### MLflow Integration
All Spark pipeline runs are automatically logged to MLflow with:
- Spark configuration parameters
- Dataset statistics and data quality metrics
- Model performance metrics for all algorithms
- Feature importance and model artifacts
- Execution time and resource utilization

## üîß Troubleshooting

### Common Issues

1. **Memory Errors**
   ```yaml
   # Increase executor memory
   spark.executor.memory: "8g"
   spark.driver.memory: "4g"
   ```

2. **Slow Performance**
   ```yaml
   # Optimize shuffle partitions
   spark.sql.shuffle.partitions: "400"  # 2-3x cores
   ```

3. **Arrow Compatibility**
   ```yaml
   # Disable Arrow if issues
   spark.sql.execution.arrow.pyspark.enabled: "false"
   ```

### Best Practices

1. **Data Partitioning** - Ensure balanced partitions (~100-200MB per partition)
2. **Caching Strategy** - Cache frequently accessed DataFrames
3. **Resource Tuning** - Monitor Spark UI and adjust executor/driver resources
4. **Cluster Mode** - Use cluster mode for production workloads

## üìà Example Performance Comparison

| Dataset Size | Local Pandas | Spark Local | Spark Cluster (4 nodes) |
|-------------|-------------|-------------|------------------------|
| 1M rows     | 45 seconds  | 38 seconds  | 25 seconds            |
| 10M rows    | 8 minutes   | 4 minutes   | 1.5 minutes           |
| 100M rows   | 2+ hours    | 35 minutes  | 8 minutes             |

*Results may vary based on hardware configuration and data characteristics.*

## üîÆ Future Enhancements

1. **Delta Lake Integration** - ACID transactions and time travel
2. **Structured Streaming** - Real-time data processing
3. **Kubernetes Deployment** - Container orchestration
4. **GPU Acceleration** - RAPIDS integration for ML workloads
5. **Auto-scaling** - Dynamic cluster sizing based on workload

---

This Spark-based implementation provides a solid foundation for scaling the customer churn prediction pipeline to handle enterprise-level datasets while maintaining high performance and reliability.